{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Section1: Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function is_available at 0x000002E3AB1A2020>\n",
      "2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\"cpu\")\n",
    "print(torch.cuda.is_available)\n",
    "# torch.cuda.is_available()\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get tensor back as python int\n",
    "\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix\n",
    "\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                      [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MATRIX[0])\n",
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor\n",
    "\n",
    "Tensor = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random tensors\n",
    "\n",
    "Why Random tensor?\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "\n",
    "'Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4002, 0.8898, 0.4817, 0.5716],\n",
      "        [0.4322, 0.6970, 0.6803, 0.1515],\n",
      "        [0.4387, 0.9184, 0.0676, 0.0294]])\n",
      "torch.Size([3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create random tensor of size (3, 4)\n",
    "\n",
    "random_tensor = torch.rand(3, 4)\n",
    "print(random_tensor)\n",
    "print(random_tensor.shape)\n",
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9493, 0.5982, 0.3322,  ..., 0.0128, 0.5687, 0.8183],\n",
      "         [0.7971, 0.8878, 0.2365,  ..., 0.1098, 0.8108, 0.5810],\n",
      "         [0.2172, 0.2006, 0.5173,  ..., 0.2821, 0.2446, 0.5832],\n",
      "         ...,\n",
      "         [0.4472, 0.1746, 0.3273,  ..., 0.4750, 0.8625, 0.3480],\n",
      "         [0.0980, 0.5804, 0.2699,  ..., 0.5721, 0.0281, 0.1725],\n",
      "         [0.3051, 0.1775, 0.9705,  ..., 0.1623, 0.5843, 0.5759]],\n",
      "\n",
      "        [[0.7533, 0.1584, 0.0730,  ..., 0.9103, 0.7996, 0.0411],\n",
      "         [0.0067, 0.3425, 0.3505,  ..., 0.9762, 0.5245, 0.5554],\n",
      "         [0.1197, 0.6538, 0.0977,  ..., 0.9013, 0.5483, 0.2306],\n",
      "         ...,\n",
      "         [0.8917, 0.9567, 0.4814,  ..., 0.8511, 0.2568, 0.1309],\n",
      "         [0.6706, 0.0540, 0.5587,  ..., 0.1788, 0.5230, 0.8856],\n",
      "         [0.0186, 0.4542, 0.0886,  ..., 0.8763, 0.3563, 0.6755]],\n",
      "\n",
      "        [[0.2731, 0.2749, 0.7180,  ..., 0.4891, 0.6229, 0.4773],\n",
      "         [0.1097, 0.5809, 0.4383,  ..., 0.9614, 0.5107, 0.3633],\n",
      "         [0.9622, 0.4010, 0.5077,  ..., 0.6626, 0.3748, 0.2733],\n",
      "         ...,\n",
      "         [0.5345, 0.4140, 0.3827,  ..., 0.7783, 0.6340, 0.0043],\n",
      "         [0.6230, 0.5459, 0.0163,  ..., 0.5016, 0.4392, 0.6056],\n",
      "         [0.9761, 0.1723, 0.8886,  ..., 0.2094, 0.7778, 0.0101]]])\n",
      "torch.Size([3, 244, 244])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create random tensor with similar shape to an image tensor\n",
    "\n",
    "random_image_size_tensor = torch.rand(size= (3, 244, 244)) # height, width, color channel\n",
    "print(random_image_size_tensor)\n",
    "print(random_image_size_tensor.shape)\n",
    "random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Zero & Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create tensor of all zeros\n",
    "\n",
    "zeros = torch.zeros(size= (3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create tensor of all ones\n",
    "\n",
    "ones = torch.ones(size= (3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creating range of tensors and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 12, 23, 34, 45, 56, 67, 78, 89])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use tensor.arange()\n",
    "\n",
    "tensor_step = torch.arange(start=1, end=100, step=11)\n",
    "print(tensor_step)\n",
    "\n",
    "tensor_arange = torch.arange(start=1, end=11)\n",
    "tensor_arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating tensor-like\n",
    "\n",
    "tensor_zero = torch.zeros_like(input=(tensor_arange))\n",
    "tensor_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Tensor Datatypes\n",
    "\n",
    "**Note:** Tensor datatype is one of the 3 big errors we'll run into with Pytorch & Deep learning\n",
    "1. Tensors not right datatype.\n",
    "2. Tensors not right shape.\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float16\n",
      "tensor([  1.,   4., 225.])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 4)\n",
    "\n",
    "float_32_tensor = torch.tensor([1.0, 2.0, 15.0],\n",
    "                               dtype=None, # What datatypes is the tensor (e.g. float32, float64, ...)\n",
    "                               device=None, # By default device = \"cpu\"\n",
    "                               requires_grad=False) # Whether or not to track gradiant with this operations\n",
    "print(float_32_tensor.dtype)\n",
    "\n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "print(float_16_tensor.dtype)\n",
    "\n",
    "multiple = float_16_tensor * float_32_tensor\n",
    "print(multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Getting Informations from tensors\n",
    "\n",
    "1.To do get datatype from a tensor, can use `tensor.dtype`\n",
    "2.To get shape from a tensor, can use `tensor.shape` or `tensor.size`\n",
    "3.To get device from tensor, can use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3898, 0.2948, 0.4435, 0.7690],\n",
       "        [0.3849, 0.0087, 0.6788, 0.0557],\n",
       "        [0.8582, 0.8747, 0.8283, 0.6939]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crate tensor\n",
    "\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3898, 0.2948, 0.4435, 0.7690],\n",
      "        [0.3849, 0.0087, 0.6788, 0.0557],\n",
      "        [0.8582, 0.8747, 0.8283, 0.6939]])\n",
      "Datatype of tensor: torch.float32\n",
      "Sahpe of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "#Get out detail\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Sahpe of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "*Addition\n",
    "*Subtraction\n",
    "*Multiplication (element-wise)\n",
    "*Division\n",
    "*Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Addition\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(tensor + 10)\n",
    "\n",
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9, -8, -7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subtraction\n",
    "\n",
    "print(tensor - 10)\n",
    "\n",
    "torch.sub(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Matrix multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must match (Lenear algebra):\n",
    "\n",
    "* `(3, 2) @ (3, 2)` won't work\n",
    "* `(2, 3) @ (3, 2)` will work\n",
    "* `(3, 2) @ (2, 3)` will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimension**\n",
    "\n",
    "* `(2, 3) @ (3, 2)` --> `(2, 2)`\n",
    "* `(3, 2) @ (2, 3)` --> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiplication (Element-wise)\n",
    "\n",
    "print(tensor * 10)\n",
    "\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiplication (Matrix)\n",
    "\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most  common errors  in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 27,  61,  95],\n",
      "        [ 30,  68, 106],\n",
      "        [ 33,  75, 117]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape for matrix multiplication\n",
    "\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "\n",
    "print(tensor_B.shape)\n",
    "print(tensor_A.shape)\n",
    "print(tensor_B.T.shape)\n",
    "# print(torch.matmul(tensor_A, tensor_B))   ##Will not work\n",
    "print(torch.matmul(tensor_B, tensor_A.T))\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this kind of shape issues, we can manipulate the shape of one of our tensor using **transpose**.\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A: torch.Size([3, 2]), tensor_B: torch.Size([3, 2])\n",
      "new shapes are: tensor_A: torch.Size([3, 2]) (same as before), tensor_B: torch.Size([2, 3])\n",
      "Multiplying tensor_A & tensor_B: \n",
      "Output:\n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "\n",
      "the shape of output: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shapes: tensor_A: {tensor_A.shape}, tensor_B: {tensor_B.shape}\")\n",
    "print(f\"new shapes are: tensor_A: {tensor_A.shape} (same as before), tensor_B: {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying tensor_A & tensor_B: \")\n",
    "print(\"Output:\\n\")\n",
    "\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(\"\\n\")\n",
    "print(f\"the shape of output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor aggregation (Finding min, max, mean, sum, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "print(x.dtype)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the min\n",
    "print(x.min())\n",
    "torch.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(90)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the max\n",
    "print(x.max())\n",
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the mean\n",
    "# torch.mean(x) --> #Error of 'could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long'\n",
    "\n",
    "# We have to convert the datatype to float32\n",
    "print(x.type(torch.float32).mean())\n",
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(450)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(450)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the sum\n",
    "print(x.sum())\n",
    "torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the positional min & max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() --> return the index of target tensor where the minimum value occurs\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fint the position in tensor that has the maximum value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Reshaping, Stacking, Squeezing & Unsqueezing tensors\n",
    "\n",
    "* Reshaping --> Reshape an input tensor to a defined shape\n",
    "* View --> Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking --> Combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze --> removes all '1' dimensions from a tensor\n",
    "* Unsqeeze --> add a '1' dimension to a target tensor\n",
    "* Permute --> Return a view of the input with dimensions permuted (swapped) in a certain way     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "x = torch.arange(1., 11.)\n",
    "\n",
    "print(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.]]),\n",
       " tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping \n",
    "# Add an extra dimension\n",
    "\n",
    "x_reshaped = x.reshape(10, 1) # We dont get error because (10 * 1 = 10) = x.shape\n",
    "x_reshaped2 = x.reshape(5, 2) # We dont get error because (5 * 2 = 10) = x.shape\n",
    "x_reshaped, x_reshaped2, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " tensor([[ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1, 10)\n",
    "print(z)\n",
    "\n",
    "## Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
    "\n",
    "z[: , 0] = 6\n",
    "x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([[ 6.,  6.,  6.,  6.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensor on top of each other\n",
    "x_stack = torch.stack([x, x, x, x], dim= 0)\n",
    "x_stack2 = torch.stack([x, x, x, x], dim= 1)\n",
    "# x_stack3 = torch.stack([x, x, x, x], dim= 2) # Will give error\n",
    "\n",
    "x_stack, x_stack2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sqeeze() - remove all single dimension from a target tensor\n",
    "print(x)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main tensor = tensor([ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "previous tensor: \n",
      "tensor([[ 6.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "previous shape: torch.Size([10, 1])\n",
      "\n",
      "New tensor = tensor([ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "New tensor shape = torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Main tensor = {x}\")\n",
    "print(f\"previous tensor: \\n{x_reshaped}\")\n",
    "print(f\"previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "#remove extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor = {x_squeezed}\")\n",
    "print(f\"New tensor shape = {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main tensor = tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Previous target: tensor([ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Pervious shape: torch.Size([10])\n",
      "New tensor_dim0 = tensor([[ 6.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
      "New tensor_dim0 shape = torch.Size([1, 10])\n",
      "New tensor_dim1 = \n",
      "tensor([[ 6.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "New tensor_dim1 shape = torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim\n",
    "print(f\"Main tensor = {x}\")\n",
    "print(f\"Previous target: {x_squeezed}\")\n",
    "print(f\"Pervious shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dim with unsqueeze\n",
    "x_unsqueeze = x_squeezed.unsqueeze(dim= 0)\n",
    "x_unsqueeze2 = x_squeezed.unsqueeze(dim= 1)\n",
    "\n",
    "\n",
    "print(f\"New tensor_dim0 = {x_unsqueeze}\")\n",
    "print(f\"New tensor_dim0 shape = {x_unsqueeze.shape}\")\n",
    "print(f\"New tensor_dim1 = \\n{x_unsqueeze2}\")\n",
    "print(f\"New tensor_dim1 shape = {x_unsqueeze2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor shape: torch.Size([224, 224, 3])\n",
      "\n",
      "\n",
      "New tensor shape + torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of a target tensor in a specific order (common use in images)\n",
    "x_images = torch.rand(224, 224, 3) # [Height, Width, Color channels]\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permute = x_images.permute(dims = (2, 0, 1)) # shifts axis  0->1, 1->2, 2->0 (we are talking about index)\n",
    "\n",
    "# print(f\"Previous tensor: {x_images}\") # too long\n",
    "print(f\"Previous tensor shape: {x_images.shape}\")\n",
    "print(\"\\n\")\n",
    "# print(f\"New tensor = {x_permute}\") # too long\n",
    "print(f\"New tensor shape + {x_permute.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
